{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zhuanlan.zhihu.com/p/24874356260\n",
    "\n",
    "#################################################### <start> é…ç½® HuggingFace å’Œ WandB <start> ####################################################\n",
    "# from huggingface_hub import login\n",
    "# hf_token = \"XXX\"  #åˆ°å®˜ç½‘å…è´¹ç”³è¯·ä¸€ä¸ª\n",
    "# login(hf_token)\n",
    "\n",
    "# import wandb\n",
    "# wb_token = \"XXX\"  #åˆ°å®˜ç½‘å…è´¹ç”³è¯·ä¸€ä¸ª\n",
    "# wandb.login(key=wb_token)\n",
    "# run = wandb.init(\n",
    "#     project='fine-tune-DeepSeek-R1-Distill-Qwen-14B on xhs Dataset',\n",
    "#     job_type=\"training\",\n",
    "#     anonymous=\"allow\"\n",
    "# )\n",
    "#################################################### </end> é…ç½® HuggingFace å’Œ WandB </end> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "#################################################### <start> åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ <start> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "# from unsloth import FastLanguageModel\n",
    "\n",
    "# max_seq_length = 2048\n",
    "# dtype = None\n",
    "# load_in_4bit = True\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     dtype = dtype,\n",
    "#     load_in_4bit = load_in_4bit,  # 4bité‡åŒ–åŠ è½½\n",
    "#     token = hf_token,\n",
    "# )\n",
    "#################################################### </end> åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ </end> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "#################################################### <start> è®­ç»ƒæ¨¡ç‰ˆ <start> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "train_prompt_style = \"\"\"\n",
    "ä»¥ä¸‹æ˜¯ä¸€é¡¹ä»»åŠ¡è¯´æ˜ï¼Œå¹¶é™„å¸¦äº†æ›´è¯¦ç»†çš„èƒŒæ™¯ä¿¡æ¯ã€‚\n",
    "è¯·æ’°å†™ä¸€ä¸ªæ»¡è¶³å®Œæˆè¯·æ±‚çš„å›å¤ã€‚\n",
    "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†è€ƒè™‘é—®é¢˜ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªé€æ­¥çš„æ€è€ƒé“¾ï¼Œä»¥ç¡®ä¿é€»è¾‘å’Œå‡†ç¡®çš„å›ç­”ã€‚\n",
    "\n",
    "### Instruction:\n",
    "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å°çº¢ä¹¦æ–‡æ¡ˆä¸“å®¶\n",
    "è¯·ä½ æ ¹æ®ä»¥ä¸‹é—®é¢˜å®Œæˆå†™ä½œ\n",
    "### Question:\n",
    "{}\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>n:\n",
    "\"\"\"\n",
    "# EOS_TOKEN = tokenizer.eos_token\n",
    "#################################################### </end> è®­ç»ƒæ¨¡ç‰ˆ </end> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "#################################################### <start> å®šä¹‰å‡½æ•°ï¼Œè®©æ•°æ®é›†å¡«å…¥æ¨¡ç‰ˆ <start> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "import re  # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—\n",
    "# ä½¿ç”¨æ­£åˆ™æå–æ€è€ƒé“¾å’Œæœ€ç»ˆå“åº”\n",
    "def formatting_prompts_func(examples):\n",
    "    # æå–æ•°æ®é›†é‡Œçš„ instructions å’Œ outputs ï¼ˆæœ¬æ¬¡æ•°æ®é›†çš„ think éƒ¨åˆ†èåˆåœ¨ outputs é‡Œï¼‰\n",
    "    instructions = examples[\"instruction\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction_text, output_text in zip(instructions, outputs):\n",
    "        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– outputs é‡Œ <think> å’Œ </think> ä¹‹é—´çš„å†…å®¹ä½œä¸º cots\n",
    "        match = re.search(r\"<think>(.*?)</think>\", output_text, re.DOTALL)\n",
    "        cot = match.group(1).strip() if match else \"\"\n",
    "\n",
    "        # æå– </think> ä¹‹åçš„å†…å®¹ä½œä¸º outputs\n",
    "        output = output_text.replace(match.group(0), \"\").strip() if match else output_text.strip()\n",
    "\n",
    "        #text = train_prompt_style.format(instruction_text, cot, output) + EOS_TOKEN\n",
    "        text = train_prompt_style.format(instruction_text, cot, output) \n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "#################################################### </end> å®šä¹‰å‡½æ•°ï¼Œè®©æ•°æ®é›†å¡«å…¥æ¨¡ç‰ˆ </end> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "#################################################### <start> è¯»å–æ•°æ®é›†ï¼Œåº”ç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•° <start> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = r'E:\\pythonCode\\FineTune\\XiaoHongShu\\Dataset\\xhs_data.json'\n",
    "dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "\n",
    "# ä½¿ç”¨ map å‡½æ•°è¿›è¡Œæ•°æ®å¤„ç†\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "#################################################### </end> è¯»å–æ•°æ®é›†ï¼Œåº”ç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•° </end> ####################################################\n",
    "#************************************************************************************************************************************************\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d49227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 798), match='<think>\\nå¥½çš„ï¼Œç”¨æˆ·è®©æˆ‘å†™ä¸€ç¯‡å°çº¢ä¹¦é£æ ¼çš„å¸–å­ï¼Œæ ‡é¢˜æ˜¯â€œğŸ‘ç§‘é¢œæ°ç”·å£«æŠ¤è‚¤ç³»åˆ—ä½¿ç”¨å¿ƒå¾—â€ã€‚é¦–>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "data_files = r'E:\\pythonCode\\FineTune\\XiaoHongShu\\Dataset\\xhs_data.json'\n",
    "dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "instructions = dataset[\"instruction\"]\n",
    "outputs = dataset[\"output\"]\n",
    "match = re.search(r\"<think>(.*?)</think>\", outputs[0], re.DOTALL)\n",
    "match\n",
    "# print(\"instructions:\", instructions[0])\n",
    "# print(\"outputs:\", outputs[0])\n",
    "# print(\"zip:\",zip(instructions, outputs))\n",
    "#for instruction_text, output_text in zip(instructions, outputs):\n",
    "    #print(\"instruction_text:\", instruction_text)\n",
    "    #print(\"output_text:\", output_text)\n",
    "    # match = re.search(r\"<think>(.*?)</think>\", output_text, re.DOTALL)\n",
    "    # print(\"match:\", match)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c9c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
